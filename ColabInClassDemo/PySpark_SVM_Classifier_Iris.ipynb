{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4a213b31",
      "metadata": {
        "id": "4a213b31"
      },
      "source": [
        "This workshop demonstrate how to apply SVM classifier on multi-class classification\n",
        "The dataset is iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pyspark and findspark\n",
        "!pip install --ignore-install -q pyspark\n",
        "# Install findspark library\n",
        "!pip install --ignore-install -q findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIhi52RWN908",
        "outputId": "3ee82ee4-0e77-4aef-cf91-44bd3f735d45"
      },
      "id": "qIhi52RWN908",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "Kz-546NFN95K"
      },
      "id": "Kz-546NFN95K",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "844ff905",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "844ff905",
        "outputId": "4da0a502-cabe-434a-ed2b-8549b10efc16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.version_info\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THyKtSjaOK1Y",
        "outputId": "049ac9f5-d097-4603-cece-9e7216434426"
      },
      "id": "THyKtSjaOK1Y",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4078110e",
      "metadata": {
        "id": "4078110e"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "from pyspark.ml.classification import OneVsRest\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ed1b26e3",
      "metadata": {
        "id": "ed1b26e3"
      },
      "outputs": [],
      "source": [
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"IrisSVM\").getOrCreate()\n",
        "\n",
        "# Load the Iris dataset into a DataFrame\n",
        "# Replace 'iris_data.csv' with the path to your dataset file\n",
        "data = spark.read.csv(\"/content/drive/MyDrive/iris-data.csv\", header=True, inferSchema=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "22895bb2",
      "metadata": {
        "id": "22895bb2"
      },
      "outputs": [],
      "source": [
        "# Define the feature columns\n",
        "feature_columns = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "571fb00d",
      "metadata": {
        "id": "571fb00d"
      },
      "outputs": [],
      "source": [
        "# Create a StringIndexer to encode the \"species\" column\n",
        "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
        "data = indexer.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f4f058ff",
      "metadata": {
        "id": "f4f058ff"
      },
      "outputs": [],
      "source": [
        "# Create a vector assembler to combine feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0be4b1c6",
      "metadata": {
        "id": "0be4b1c6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=123)\n",
        "\n",
        "# Create an SVM classifier\n",
        "svm = LinearSVC(maxIter=100, labelCol=\"label\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b2b9e889",
      "metadata": {
        "scrolled": true,
        "id": "b2b9e889"
      },
      "outputs": [],
      "source": [
        "# Create an OvR classifier\n",
        "ovr_classifier = OneVsRest(classifier=svm, labelCol=\"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e03ac930",
      "metadata": {
        "id": "e03ac930"
      },
      "outputs": [],
      "source": [
        "# Train the OvR model\n",
        "ovr_model = ovr_classifier.fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "37d4868e",
      "metadata": {
        "id": "37d4868e"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "predictions = ovr_model.transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d27446d6",
      "metadata": {
        "id": "d27446d6"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9e78dd16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e78dd16",
        "outputId": "26f0c18e-2a0a-4cf7-a892-b8e6e130163d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.10%\n"
          ]
        }
      ],
      "source": [
        "# Print the accuracy of the model\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e4e4e767",
      "metadata": {
        "id": "e4e4e767"
      },
      "outputs": [],
      "source": [
        "# Convert the predictions and labels to RDD for MulticlassMetrics\n",
        "prediction_and_label = predictions.select(\"prediction\", \"label\").rdd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a7c5859f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7c5859f",
        "outputId": "d4440b91-9f32-456c-ce66-3ae06f40cc4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Instantiate MulticlassMetrics\n",
        "metrics = MulticlassMetrics(prediction_and_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3e3f57a8",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e3f57a8",
        "outputId": "a6f226db-4668-4f05-d2ab-d765903f7b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[13.  0.  0.]\n",
            " [ 0.  6.  1.]\n",
            " [ 0.  1.  8.]]\n"
          ]
        }
      ],
      "source": [
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(metrics.confusionMatrix().toArray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5140b721",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5140b721",
        "outputId": "2320e162-c9c4-463b-cbd4-b44920a99bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall for Setosa class: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Get the recall for the \"Setosa\" class (class index 0)\n",
        "setosa_recall = metrics.recall(0)\n",
        "\n",
        "# Print the recall for the \"Setosa\" class\n",
        "print(f\"Recall for Setosa class: {setosa_recall:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b089c3e8",
      "metadata": {
        "id": "b089c3e8"
      },
      "outputs": [],
      "source": [
        "# Stop the Spark session\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e017849",
      "metadata": {
        "id": "2e017849"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}