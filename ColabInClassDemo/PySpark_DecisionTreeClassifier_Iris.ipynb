{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install pyspark and findspark\n",
        "!pip install --ignore-install -q pyspark\n",
        "# Install findspark library\n",
        "!pip install --ignore-install -q findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4Lqkc31PgkF",
        "outputId": "cd96d908-8db4-47f3-d2f2-6be6129b9bac"
      },
      "id": "U4Lqkc31PgkF",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "FoiOub3qPgpV"
      },
      "id": "FoiOub3qPgpV",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.version_info\n",
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HzAO31ePgtI",
        "outputId": "13cc7d6e-1d2b-4a3e-8af0-888eac294197"
      },
      "id": "3HzAO31ePgtI",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF_-3nS8PnWh",
        "outputId": "96c4d675-94d2-4fb9-fe98-124066bffbb4"
      },
      "id": "vF_-3nS8PnWh",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77995cdc",
      "metadata": {
        "id": "77995cdc"
      },
      "source": [
        "### 1. Set up spark context and SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "63d077ba",
      "metadata": {
        "id": "63d077ba"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b2b8c86d",
      "metadata": {
        "id": "b2b8c86d"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"PySpark-DecisitonTreeClassifier_Iris\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e70dff",
      "metadata": {
        "id": "14e70dff"
      },
      "source": [
        "### 2. Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e11c16ad",
      "metadata": {
        "id": "e11c16ad"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset (assuming you have it in a CSV format)\n",
        "iris_data = spark.read.csv(\"/content/drive/MyDrive/iris-data.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "301ae7cf",
      "metadata": {
        "id": "301ae7cf"
      },
      "outputs": [],
      "source": [
        "# Let's assume that the \"class\" column is our target variable (label)\n",
        "# and the other columns are our features\n",
        "feature_cols = iris_data.columns[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "64ebb9fd",
      "metadata": {
        "id": "64ebb9fd"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "# Convert string labels into numerical labels\n",
        "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
        "iris_data = indexer.fit(iris_data).transform(iris_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b7a10123",
      "metadata": {
        "id": "b7a10123"
      },
      "outputs": [],
      "source": [
        "# Create a feature vector by assembling the feature columns\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "data = assembler.transform(iris_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d5a6f8f0",
      "metadata": {
        "id": "d5a6f8f0"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "(training_data, testing_data) = data.randomSplit([0.8, 0.2], seed=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4415063",
      "metadata": {
        "id": "b4415063"
      },
      "source": [
        "### 3. Create DecisionTree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "68369e5a",
      "metadata": {
        "id": "68369e5a"
      },
      "outputs": [],
      "source": [
        "# Create a DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=5, minInfoGain=0.001, impurity=\"entropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7bc2abb5",
      "metadata": {
        "id": "7bc2abb5"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model = dt.fit(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "eb3b3263",
      "metadata": {
        "id": "eb3b3263"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the testing data\n",
        "predictions = model.transform(testing_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2063224e",
      "metadata": {
        "id": "2063224e"
      },
      "source": [
        "### 3. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2ddb0265",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ddb0265",
        "outputId": "29cf3222-b66a-478b-e217-24502d3647d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.93\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "# Evaluate the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a837404c",
      "metadata": {
        "id": "a837404c"
      },
      "source": [
        "### 4. Feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8149a986",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8149a986",
        "outputId": "e083c849-04cd-4449-b532-522771705ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 'sepal length': 0.03\n",
            "Feature 'sepal width': 0.00\n",
            "Feature 'petal length': 0.63\n",
            "Feature 'petal width': 0.34\n"
          ]
        }
      ],
      "source": [
        "feature_importance = model.featureImportances.toArray()\n",
        "\n",
        "# Show feature importance\n",
        "for i, column in enumerate(assembler.getInputCols()):\n",
        "    print(f\"Feature '{column}': {feature_importance[i]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f0cba34",
      "metadata": {
        "id": "7f0cba34"
      },
      "source": [
        "### 5. Visualize the Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "dbf812e4",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbf812e4",
        "outputId": "033d41ec-e514-4634-e4b0-3cad714f89b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_9314f6319ad3, depth=4, numNodes=15, numClasses=3, numFeatures=4\n",
            "  If (feature 2 <= 2.45)\n",
            "   Predict: 0.0\n",
            "  Else (feature 2 > 2.45)\n",
            "   If (feature 3 <= 1.75)\n",
            "    If (feature 2 <= 4.95)\n",
            "     If (feature 3 <= 1.65)\n",
            "      Predict: 1.0\n",
            "     Else (feature 3 > 1.65)\n",
            "      Predict: 2.0\n",
            "    Else (feature 2 > 4.95)\n",
            "     If (feature 0 <= 6.35)\n",
            "      Predict: 2.0\n",
            "     Else (feature 0 > 6.35)\n",
            "      Predict: 1.0\n",
            "   Else (feature 3 > 1.75)\n",
            "    If (feature 2 <= 4.85)\n",
            "     If (feature 0 <= 5.95)\n",
            "      Predict: 1.0\n",
            "     Else (feature 0 > 5.95)\n",
            "      Predict: 2.0\n",
            "    Else (feature 2 > 4.85)\n",
            "     Predict: 2.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.toDebugString)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e7afa755",
      "metadata": {
        "scrolled": true,
        "id": "e7afa755"
      },
      "outputs": [],
      "source": [
        "# Stop the Spark session\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}