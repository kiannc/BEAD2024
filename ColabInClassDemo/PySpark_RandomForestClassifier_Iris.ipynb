{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install pyspark and findspark\n",
        "!pip install --ignore-install -q pyspark\n",
        "# Install findspark library\n",
        "!pip install --ignore-install -q findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47uJH4pmRhZ-",
        "outputId": "3af5f567-a9b7-4645-9d29-0c44da90aa07"
      },
      "id": "47uJH4pmRhZ-",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "X1p6r_tfRgPP"
      },
      "id": "X1p6r_tfRgPP",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKRE6PDpRlOD",
        "outputId": "f695d0be-1bb5-4a71-98c4-8be3f8e9eff5"
      },
      "id": "zKRE6PDpRlOD",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aef7a115",
      "metadata": {
        "id": "aef7a115"
      },
      "source": [
        "### 1. Set up spark context and SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "37fee105",
      "metadata": {
        "id": "37fee105"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "74e93c53",
      "metadata": {
        "id": "74e93c53"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"PySpark-RandomForestClassifier_Iris\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08b6bc96",
      "metadata": {
        "id": "08b6bc96"
      },
      "source": [
        "### 2. Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "973ed743",
      "metadata": {
        "id": "973ed743"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset (assuming you have it in a CSV format)\n",
        "iris_data = spark.read.csv(\"/content/drive/MyDrive/iris-data.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "840d1e43",
      "metadata": {
        "id": "840d1e43"
      },
      "outputs": [],
      "source": [
        "# Assuming the target variable is \"class\" and other columns are features\n",
        "feature_cols = iris_data.columns[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "83b0c85d",
      "metadata": {
        "id": "83b0c85d"
      },
      "outputs": [],
      "source": [
        "# Convert string labels into numerical labels\n",
        "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
        "iris_data = indexer.fit(iris_data).transform(iris_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a9a14fe6",
      "metadata": {
        "id": "a9a14fe6"
      },
      "outputs": [],
      "source": [
        "# Create a feature vector by assembling the feature columns\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "data = assembler.transform(iris_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dca96493",
      "metadata": {
        "id": "dca96493"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "(training_data, testing_data) = data.randomSplit([0.8, 0.2], seed=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "690a235e",
      "metadata": {
        "id": "690a235e"
      },
      "outputs": [],
      "source": [
        "# Customized parameters\n",
        "num_trees = 10\n",
        "max_depth = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dd505adc",
      "metadata": {
        "id": "dd505adc"
      },
      "outputs": [],
      "source": [
        "# Create and train a RandomForestClassifier with customized parameters\n",
        "rf = RandomForestClassifier(\n",
        "    labelCol=\"label\",\n",
        "    featuresCol=\"features\",\n",
        "    numTrees=num_trees,\n",
        "    maxDepth=max_depth\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5da887dc",
      "metadata": {
        "id": "5da887dc"
      },
      "outputs": [],
      "source": [
        "model = rf.fit(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "47271c59",
      "metadata": {
        "id": "47271c59"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the testing data\n",
        "predictions = model.transform(testing_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3facc32f",
      "metadata": {
        "id": "3facc32f"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "700c793d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "700c793d",
        "outputId": "140c47ec-f18e-47a4-e7ba-ac134aaaead2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97\n"
          ]
        }
      ],
      "source": [
        "# Print the accuracy\n",
        "print(\"Accuracy: {:.2f}\".format(accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "fda6a0d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fda6a0d1",
        "outputId": "79a72b4a-6659-4cb6-c6ad-921de2df59e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:  (4,[0,1,2,3],[0.10971043638291314,0.027259903033869593,0.5388647415001908,0.3241649190830265])\n"
          ]
        }
      ],
      "source": [
        "# Show the feature importances\n",
        "print(\"Feature Importances: \", model.featureImportances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "349da959",
      "metadata": {
        "id": "349da959"
      },
      "outputs": [],
      "source": [
        "# Stop the Spark session\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "121f24af",
      "metadata": {
        "id": "121f24af"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}