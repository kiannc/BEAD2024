{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pyspark and findspark\n",
    "!pip install --ignore-install -q pyspark\n",
    "# Install findspark library\n",
    "!pip install --ignore-install -q findspark\n",
    "# Import findspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('lr_example').getOrCreate()\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Load data\n",
    "all_data = spark.read.format(\"libsvm\").option(\"numFeatures\",\"10\").load('/content/drive/MyDrive/sample_linear_regression_data.txt')\n",
    "# Split into training data and test data\n",
    "train_data, test_data = all_data.randomSplit([0.7,0.3])\n",
    "train_data.show()\n",
    "test_data.show()\n",
    "unlabeled_data = test_data.select(\"features\")\n",
    "unlabeled_data.show()\n",
    "# These are the default values for the featuresCol, labelCol, predictionCol\n",
    "lr = LinearRegression(featuresCol='features',labelCol='label',predictionCol='prediction')\n",
    "# Fit the model\n",
    "lr_model = lr.fit(train_data)\n",
    "# Print the coefficients and intercept training data\n",
    "print(\"Coefficients: {}\".format(str(lr_model.coefficients)))\n",
    "print(\"Intercept: {}\".format(str(lr_model.intercept)))\n",
    "# Testing result\n",
    "test_result = lr_model.evaluate(test_data)\n",
    "test_result.residuals.show()\n",
    "print(\"RMSE: {}\".format(test_result.rootMeanSquaredError))\n",
    "# Prediction\n",
    "predictions = lr_model.transform(unlabeled_data)\n",
    "predictions.show()\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
