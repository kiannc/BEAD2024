{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMv+GfOPM0fYsVVcCL0PdyM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wh66ILgHciVp","executionInfo":{"status":"ok","timestamp":1697442404821,"user_tz":-480,"elapsed":59002,"user":{"displayName":"Fan Liu","userId":"08772667987348844113"}},"outputId":"e71bb8f6-219d-4828-8aa2-f0d536f99758"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# Install pyspark and findspark\n","!pip install --ignore-install -q pyspark\n","# Install findspark library\n","!pip install --ignore-install -q findspark"]},{"cell_type":"code","source":["# Import findspark\n","import findspark\n","findspark.init()"],"metadata":{"id":"hFDBDMjMci6p","executionInfo":{"status":"ok","timestamp":1697442407739,"user_tz":-480,"elapsed":7,"user":{"displayName":"Fan Liu","userId":"08772667987348844113"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPG8iYCzci_j","executionInfo":{"status":"ok","timestamp":1697442430812,"user_tz":-480,"elapsed":20173,"user":{"displayName":"Fan Liu","userId":"08772667987348844113"}},"outputId":"b098c57a-3a10-404e-938e-b515e1044ead"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","# Start SparkSession\n","spark = SparkSession.builder.appName(\"missingdata\").getOrCreate()\n","df = spark.read.csv('/content/drive/MyDrive/ContainsNull.csv',header=True,inferSchema=True)\n","df.show()\n","\n","# Drop any row that contains missing data\n","df.na.drop().show()\n","# Has to have at least 2 NON-null values\n","df.na.drop(thresh=2).show()\n","# Drop row “Sales” contains missing data\n","df.na.drop(subset=[\"Sales\"]).show()\n","# Drop any row contains missing data\n","df.na.drop(how='any').show()\n","# Drop those rows contains missing data for all columns\n","df.na.drop(how='all').show()\n","\n","# Fill missing data with “NEW VALUE”\n","df.na.fill('NEW VALUE').show()\n","# Fill missing data with 0\n","df.na.fill(0).show()\n","# Fill missing data in row “Name” with “No Name”\n","df.na.fill('No Name',subset=['Name']).show()\n","# Fill values with mean value for column “Sales”\n","import pyspark.sql.functions as F\n","mean_val = df.select(F.mean(df['Sales'])).collect()\n","# Weird nested formatting of Row object!\n","mean_val[0][0]\n","mean_sales = mean_val[0][0]\n","df.na.fill(mean_sales,[\"Sales\"]).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96fBKrRrcjCK","executionInfo":{"status":"ok","timestamp":1697442462352,"user_tz":-480,"elapsed":28114,"user":{"displayName":"Fan Liu","userId":"08772667987348844113"}},"outputId":"d333898a-d966-4fb1-cb34-8ed78baf70d0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-----+-----+\n","|  Id| Name|Sales|\n","+----+-----+-----+\n","|emp1| John| NULL|\n","|emp2| NULL| NULL|\n","|emp3| NULL|345.0|\n","|emp4|Cindy|456.0|\n","+----+-----+-----+\n","\n","+----+-----+-----+\n","|  Id| Name|Sales|\n","+----+-----+-----+\n","|emp4|Cindy|456.0|\n","+----+-----+-----+\n","\n","+----+-----+-----+\n","|  Id| Name|Sales|\n","+----+-----+-----+\n","|emp1| John| NULL|\n","|emp3| NULL|345.0|\n","|emp4|Cindy|456.0|\n","+----+-----+-----+\n","\n","+----+-----+-----+\n","|  Id| Name|Sales|\n","+----+-----+-----+\n","|emp3| NULL|345.0|\n","|emp4|Cindy|456.0|\n","+----+-----+-----+\n","\n","+----+-----+-----+\n","|  Id| Name|Sales|\n","+----+-----+-----+\n","|emp4|Cindy|456.0|\n","+----+-----+-----+\n","\n","+----+-----+-----+\n","|  Id| Name|Sales|\n","+----+-----+-----+\n","|emp1| John| NULL|\n","|emp2| NULL| NULL|\n","|emp3| NULL|345.0|\n","|emp4|Cindy|456.0|\n","+----+-----+-----+\n","\n","+----+---------+-----+\n","|  Id|     Name|Sales|\n","+----+---------+-----+\n","|emp1|     John| NULL|\n","|emp2|NEW VALUE| NULL|\n","|emp3|NEW VALUE|345.0|\n","|emp4|    Cindy|456.0|\n","+----+---------+-----+\n","\n","+----+-----+-----+\n","|  Id| Name|Sales|\n","+----+-----+-----+\n","|emp1| John|  0.0|\n","|emp2| NULL|  0.0|\n","|emp3| NULL|345.0|\n","|emp4|Cindy|456.0|\n","+----+-----+-----+\n","\n","+----+-------+-----+\n","|  Id|   Name|Sales|\n","+----+-------+-----+\n","|emp1|   John| NULL|\n","|emp2|No Name| NULL|\n","|emp3|No Name|345.0|\n","|emp4|  Cindy|456.0|\n","+----+-------+-----+\n","\n","+----+-----+-----+\n","|  Id| Name|Sales|\n","+----+-----+-----+\n","|emp1| John|400.5|\n","|emp2| NULL|400.5|\n","|emp3| NULL|345.0|\n","|emp4|Cindy|456.0|\n","+----+-----+-----+\n","\n"]}]},{"cell_type":"code","source":["spark.stop()"],"metadata":{"id":"nVlp8Sj8dBOr"},"execution_count":null,"outputs":[]}]}